{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>2.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>2.103739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516523</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe        Type  \n",
       "count  214.000000  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009    2.780374  \n",
       "std      1.423153    0.497219    0.097439    2.103739  \n",
       "min      5.430000    0.000000    0.000000    1.000000  \n",
       "25%      8.240000    0.000000    0.000000    1.000000  \n",
       "50%      8.600000    0.000000    0.000000    2.000000  \n",
       "75%      9.172500    0.000000    0.100000    3.000000  \n",
       "max     16.190000    3.150000    0.510000    7.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass = pd.read_csv('glass.csv')\n",
    "glass.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (128, 10)\n",
      "test (86, 10)\n",
      "X_train (128, 9)\n",
      "y_train (128,)\n",
      "X_test (86, 9)\n",
      "y_test (86,)\n"
     ]
    }
   ],
   "source": [
    "# Dividir o dados para treinamento e teste\n",
    "train, test = train_test_split(glass, test_size=.4, random_state=123)\n",
    "\n",
    "print('train {0}'.format(train.shape))\n",
    "print('test {0}'.format(test.shape))\n",
    "\n",
    "X_train = train.drop(['Type'], axis=1)\n",
    "y_train = train['Type']\n",
    "\n",
    "X_test = test.drop(['Type'], axis=1)\n",
    "y_test = test['Type']\n",
    "\n",
    "print('X_train {0}'.format(X_train.shape))\n",
    "print('y_train {0}'.format(y_train.shape))\n",
    "print('X_test {0}'.format(X_test.shape))\n",
    "print('y_test {0}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.72        23\n",
      "           2       0.67      0.90      0.76        29\n",
      "           3       0.00      0.00      0.00         6\n",
      "           5       0.75      0.38      0.50         8\n",
      "           6       1.00      0.50      0.67         4\n",
      "           7       0.81      0.81      0.81        16\n",
      "\n",
      "   micro avg       0.71      0.71      0.71        86\n",
      "   macro avg       0.66      0.55      0.58        86\n",
      "weighted avg       0.68      0.71      0.68        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jecs89/anaconda3/envs/tutorialConda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: [0.75       0.73333333 0.73333333 0.78571429 0.71428571 0.5\n",
      " 0.75       0.7        0.6        0.6       ]\n",
      "avg accuracy: 0.6866666666666666\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "# k=10 sobre o set de treinamento, bagging\n",
    "X = train.drop(['Type'], axis=1)\n",
    "y = train.Type\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "print('accuracy:', scores)\n",
    "print('avg accuracy:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.70      0.68        23\n",
      "           2       0.68      0.72      0.70        29\n",
      "           3       0.40      0.33      0.36         6\n",
      "           5       0.83      0.62      0.71         8\n",
      "           6       0.60      0.75      0.67         4\n",
      "           7       0.93      0.88      0.90        16\n",
      "\n",
      "   micro avg       0.71      0.71      0.71        86\n",
      "   macro avg       0.69      0.67      0.67        86\n",
      "weighted avg       0.71      0.71      0.71        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# avaliando o algoritmo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: [0.75       0.46666667 0.8        0.64285714 0.42857143 0.33333333\n",
      " 0.66666667 0.7        0.6        0.5       ]\n",
      "avg accuracy: 0.5888095238095238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jecs89/anaconda3/envs/tutorialConda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "# k=10 sobre o set de treinamento, clf\n",
    "X = train.drop(['Type'], axis=1)\n",
    "y = train.Type\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print('accuracy:', scores)\n",
    "print('avg accuracy:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Haciendo la matriz de confusion binaria para la clase i\n",
    "def MultiClassConfusionMatrix(y_true,y_pred):\n",
    "    \n",
    "    C= np.unique(y_true)\n",
    "    D=len(C)\n",
    "    \n",
    "    # Matriz de confusion general \n",
    "    CM=confusion_matrix(y_true, y_pred)\n",
    "    #print('###### General Confusion Matrix #####')\n",
    "    #print(CM)\n",
    "        \n",
    "    accuracy=np.zeros(D)\n",
    "    precision=np.zeros(D)\n",
    "    recall=np.zeros(D)\n",
    "    specificity=np.zeros(D)\n",
    "    clase = []#np.zeros(D, dtype = int)\n",
    "    \n",
    "    \n",
    "    for i in range(D):\n",
    "        #atrib=np.array(C)\n",
    "        #print('aquiii')\n",
    "        #print(C)\n",
    "        atributo=C[i]\n",
    "        row_i=CM[i,:]\n",
    "        col_i=CM[:,i]\n",
    "        \n",
    "        row_i_without_i=np.delete(row_i,i,0)\n",
    "        #print(row_i_without_i)\n",
    "        col_i_without_i=np.delete(col_i,i,0)\n",
    "        del_row_i=np.delete(CM,i,0)\n",
    "        del_col_i=np.delete(del_row_i,i,1)\n",
    "        \n",
    "        VP=CM[i,i]\n",
    "        #print(VP)\n",
    "        FN=np.sum(row_i_without_i)\n",
    "        #print(VN)\n",
    "        FP=np.sum(col_i_without_i)\n",
    "        VN=np.sum(del_col_i)\n",
    "#         print('VP VN FP FN', VP, VN,FP,FN )\n",
    "        \n",
    "        CM_new=[[VP,FN],[FP,VN]]\n",
    "        #print(CM_new)\n",
    "        CM_new=np.array(CM_new) # casting\n",
    "\n",
    "        # calculando las medidas de desempenho\n",
    "        div1=VP+VN+FP+FN\n",
    "        #print(div1)\n",
    "        div2=VP+FP\n",
    "        div3=VP+FN\n",
    "        div4=VN+FP\n",
    "        \n",
    "        accuracy[i]=save_value((VP+VN),div1)\n",
    "        precision[i]=save_value(VP,div2)\n",
    "        recall[i]=save_value(VP,div3)\n",
    "        specificity[i]=save_value(VN,div4)        \n",
    "        clase.append(atributo)\n",
    "        \n",
    "        \n",
    "        #print('###### Confusion Matrix para clase ',atributo, ' #####')\n",
    "        #print(CM_new)    \n",
    "        \n",
    "    Table = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'specificity': specificity, 'clase': clase}\n",
    "    df = pd.DataFrame(data=Table)\n",
    "    print(df)\n",
    "    aux = df.sum(axis = 0, skipna = True)\n",
    "    #print('df.shape')\n",
    "    #print(df.shape[0])\n",
    "    mean = aux[0] / df.shape[0]\n",
    "    print('   mean accuracy: ', mean)\n",
    "    #print(accuracy.shape)\n",
    "#     return accuracy\n",
    "    #print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SALIDA RANDOM FOREST\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9ddfba72b008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SALIDA RANDOM FOREST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mMultiClassConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_target_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_pred_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SALIDA ONLY TREE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-656b54ba491d>\u001b[0m in \u001b[0;36mMultiClassConfusionMatrix\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mdiv4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mVN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mrecall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_value' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "glass = pd.read_csv('glass.csv')\n",
    "glass_data = glass.values\n",
    "#X = df.iloc[:, 0:4]\n",
    "#y = df.iloc[:, 4]\n",
    "\n",
    "y_glass = glass_data[:, 9]\n",
    "x_glass = glass_data[:, 0:9]\n",
    "#y_glass = glass.iloc[:, 10]\n",
    "#x_glass = glass.iloc[:, 1:10]\n",
    "#x_glass_data = x_glass.values\n",
    "#y_glass_data = y_glass.values\n",
    "\n",
    "\n",
    "best_accuracy_f = 0\n",
    "best_pred_f     = []\n",
    "best_target_f   = []\n",
    "\n",
    "best_accuracy_t = 0\n",
    "best_pred_t     = []\n",
    "best_target_t   = []\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "for train_index, test_index in kf.split(x_glass):\n",
    "    #x_train, x_test = x_glass.iloc[train_index], x_glass.iloc[test_index]\n",
    "    #y_train, y_test = y_glass.iloc[train_index], y_glass.iloc[test_index]\n",
    "    \n",
    "    x_train, x_test = x_glass[train_index], x_glass[test_index]\n",
    "    y_train, y_test = y_glass[train_index], y_glass[test_index]\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    current_accuracy = accuracy_score(y_test, y_pred)\n",
    "    if current_accuracy > best_accuracy_f:\n",
    "        best_accuracy_f = current_accuracy\n",
    "        best_pred_f     = y_pred\n",
    "        best_target_f   = y_test\n",
    "    \n",
    "    \n",
    "    t_clf = DecisionTreeClassifier(criterion = 'gini')\n",
    "    t_clf.fit(x_train, y_train)\n",
    "    y_pred_t = t_clf.predict(x_test)        \n",
    "    current_accuracy_t = accuracy_score(y_test, y_pred_t)\n",
    "    \n",
    "    if current_accuracy_t > best_accuracy_t:\n",
    "        best_accuracy_t = current_accuracy        \n",
    "        best_pred_t     = y_pred_t\n",
    "        best_target_t   = y_test\n",
    "\n",
    "        \n",
    "print('SALIDA RANDOM FOREST')\n",
    "MultiClassConfusionMatrix(best_target_f, best_pred_f)\n",
    "\n",
    "print('SALIDA ONLY TREE')\n",
    "MultiClassConfusionMatrix(best_target_t, best_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
