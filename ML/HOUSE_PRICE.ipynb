{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Caregando o arquivo\n",
    "df = pd.read_csv('./house-prices-advanced-regression-techniques/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando os atributos para a exploração\n",
    "df.shape[0]\n",
    "df['LotFrontage'][0]\n",
    "\n",
    "mydf = df[['LotArea','Street','BldgType','HouseStyle','OverallQual', 'OverallCond','YearBuilt','TotalBsmtSF','BedroomAbvGr','KitchenAbvGr','SalePrice']]\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Descrição do conjunto de dados selecionado, nome: mydf\n",
    "mydf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Fazendo a conversão dos atributos qualitativos \n",
    "print(mydf['Street'].value_counts())\n",
    "print(mydf['BldgType'].value_counts())\n",
    "print(mydf['HouseStyle'].value_counts())\n",
    "cleanup_nums = {\"Street\": {\"Grvl\":0, \"Pave\":1},\n",
    "                 \"BldgType\": {\"1Fam\":0, \"TwnhsE\": 1, \"Duplex\":2, \"Twnhs\":3, \"2fmCon\":4},\n",
    "                 \"HouseStyle\": {\"1Story\":0, \"2Story\":2, \"1.5Fin\":3, \"SLvl\":4, \"SFoyer\":5, \"1.5Unf\":6, \"2.5Unf\":7, \"2.5Fin\":8}}\n",
    "mydf.replace(cleanup_nums, inplace=True)\n",
    "print(mydf['Street'].value_counts())\n",
    "print(mydf['BldgType'].value_counts())\n",
    "print(mydf['HouseStyle'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando as medidas de localização e dispersão\n",
    "stats = np.zeros([5,10])\n",
    "counter = 0\n",
    "with open('stats.csv', 'w') as file:\n",
    "    for column in mydf:\n",
    "        stats[0,counter] = mydf[column].mean()\n",
    "        stats[1,counter] = mydf[column].median()\n",
    "        stats[2,counter] = mydf[column].mode()\n",
    "        stats[3,counter] = mydf[column].std()\n",
    "        stats[4,counter] = mydf[column].var()\n",
    "        #stats[3,counter] = mydf[column].skew()\n",
    "        #stats[4,counter] = mydf[column].kurt()\n",
    "        for i in range(0,5):\n",
    "            file.write( str(round(stats[i,counter],3)) + \",\"  )\n",
    "        counter += 1\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando as medidas de distribuição: Momento central para K=1,2,3,4; momento original para k=1,2; momento padronizado para k=1,2,3,4\n",
    "import math \n",
    "\n",
    "# Construimos intervalos y calculamos la frequência por cada intervalo\n",
    "k    = math.floor(1 + ((math.log(mydf['LotArea'].shape[0],2))))\n",
    "print('ElementosK')\n",
    "print(k)\n",
    "cols = ['amplitud']\n",
    "amplitud = pd.DataFrame(index = mydf.columns.values, columns =cols)\n",
    "amplitud = amplitud.fillna(0)\n",
    "for column in mydf:\n",
    "    hist, bin_edges = np.histogram(mydf[column])\n",
    "    amplitud.loc[column] = bin_edges[1] - bin_edges[0]    \n",
    "print(amplitud)\n",
    "\n",
    "def obtenerAmplitudCorrecta(column, data):\n",
    "    val_min = math.floor(mydf[column].min())     \n",
    "    amp = amplitud.at[column,'amplitud']        \n",
    "    return math.floor((data-val_min) / amp)     \n",
    "\n",
    "freq    = np.array(np.zeros((10, k)), dtype='int64')\n",
    "idx_row = 0\n",
    "for column in mydf:\n",
    "    values = np.zeros(k)\n",
    "    for i in range(0, mydf[column].shape[0]):\n",
    "        element = mydf[column][i]\n",
    "        amp_cor = obtenerAmplitudCorrecta(column, element)\n",
    "        freq[idx_row][amp_cor] += 1\n",
    "    idx_row +=1\n",
    "        \n",
    "print('FRECUENCIA')\n",
    "frecuencia = pd.DataFrame(freq)\n",
    "frecuencia = frecuencia.set_index(amplitud.index.values)\n",
    "print(frecuencia)\n",
    "print('FIN FRECUENCIA')\n",
    "\n",
    "#Momento original\n",
    "cols_original     = ['k1']\n",
    "momentos_original = pd.DataFrame(index = mydf.columns.values, columns=cols_original)\n",
    "momentos_original = momentos_original.fillna(0)\n",
    "\n",
    "cols_medio     = ['k1', 'k2', 'k3', 'k4']\n",
    "momentos_medio = pd.DataFrame(index = mydf.columns.values, columns=cols_medio)\n",
    "momentos_medio = momentos_medio.fillna(0)\n",
    "media          = mydf.mean()\n",
    "\n",
    "\n",
    "cols_padronizado     = ['k1', 'k2', 'k3', 'k4']\n",
    "momentos_padronizado = pd.DataFrame(index = mydf.columns.values, columns=cols_padronizado)\n",
    "momentos_padronizado = momentos_padronizado.fillna(0)\n",
    "varianza             = mydf.var()\n",
    "for column in mydf:\n",
    "    temp_original    = 0\n",
    "    temp_medio_k1    = 0\n",
    "    temp_medio_k2    = 0\n",
    "    temp_medio_k3    = 0\n",
    "    temp_medio_k4    = 0\n",
    "    temp_padronizado_k1 = 0\n",
    "    temp_padronizado_k2 = 0\n",
    "    temp_padronizado_k3 = 0\n",
    "    temp_padronizado_k4 = 0\n",
    "    for i in range(0, mydf[column].shape[0]):\n",
    "        element = mydf[column][i]\n",
    "        amplitud\n",
    "        amp_cor = obtenerAmplitudCorrecta(column, element)\n",
    "        amp     = amplitud.at[column,'amplitud']\n",
    "        minimo  =  mydf[column].min()\n",
    "        min_amp = minimo + (amp * amp_cor)\n",
    "        max_amp = minimo + (amp * (amp_cor + 1))\n",
    "        elemnt  = (min_amp + max_amp) / 2\n",
    "        \n",
    "        frq_temp= frecuencia.at[column, amp_cor]\n",
    "        \n",
    "        # Momento Original                \n",
    "        temp_original += frq_temp * element\n",
    "        \n",
    "        #Momento Central\n",
    "        aux = element - media[column]\n",
    "        temp_medio_k1 += aux ** 1\n",
    "        temp_medio_k2 += aux ** 2\n",
    "        temp_medio_k3 += aux ** 3\n",
    "        temp_medio_k4 += aux ** 4\n",
    "        \n",
    "        #Momento Padronizado\n",
    "        # Los momentos k = 1 , k = 2 y k = 4 el calculo inicial es parecido al del momento medio\n",
    "        temp_padronizado_k3 += (aux ** 3) * frq_temp\n",
    "        \n",
    "    \n",
    "    # Agrupando momento original\n",
    "    momentos_original.loc[column] = temp_original\n",
    "    \n",
    "    # Agrupando momento medio\n",
    "    temp_medio_k1 /= (mydf.shape[0] - 1)\n",
    "    temp_medio_k2 /= (mydf.shape[0] - 1)\n",
    "    temp_medio_k3 /= (mydf.shape[0] - 1)\n",
    "    temp_medio_k4 /= (mydf.shape[0] - 1)    \n",
    "    momentos_medio.loc[column] = pd.Series({'k1':temp_medio_k1, 'k2':temp_medio_k2, 'k3':temp_medio_k3, 'k4':temp_medio_k4})\n",
    "    \n",
    "    #Agrupando momento padronizado\n",
    "    temp_padronizado_k1 = temp_medio_k1 / (varianza[column])\n",
    "    temp_padronizado_k2 = temp_medio_k2 / (varianza[column])\n",
    "    temp_padronizado_k3 /= temp_padronizado_k3 / (varianza[column])\n",
    "    temp_padronizado_k4 = temp_medio_k4 / (varianza[column] ** 2)\n",
    "    momentos_padronizado.loc[column] = pd.Series({'k1':temp_padronizado_k1, 'k2':temp_padronizado_k2, 'k3':temp_padronizado_k3, 'k4':temp_padronizado_k4})\n",
    "\n",
    "print('******* MOMENTO ORIGINAL *******')\n",
    "print(momentos_original)\n",
    "print('******* MOMENTO CENTRAL *******')\n",
    "print(momentos_medio)\n",
    "print('******* MOMENTO PADRONIZADO *******')\n",
    "print(momentos_padronizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = [f for f in os.listdir('./') if os.path.isfile(f)]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Calculando a matriz de covariância e a correlação entre os atributos\n",
    "mydf.cov()\n",
    "mydf.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Gerando o scatter plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.plotting.scatter_matrix(mydf, alpha=0.2, figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.savefig('scatter.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Particularmente greando o scatter plot de dois atributos\n",
    "plt.scatter(df.YearBuilt, df.LotArea)\n",
    "plt.xlabel(\"YearBuilt\", fontsize = 15)\n",
    "plt.ylabel(\"LotArea\", fontsize = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Particularmente greando o scatter plot de dois atributos\n",
    "plt.scatter(df.KitchenAbvGr, df.LotArea)\n",
    "plt.xlabel(\"KitchenAbvGr\", fontsize = 15)\n",
    "plt.ylabel(\"LotArea\", fontsize = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Gerando o histograma\n",
    "counter = 1\n",
    "plt.figure(figsize = (7,7))\n",
    "for column in mydf:\n",
    "    plt.subplot(4,3,int(counter))\n",
    "    plt.title(column)\n",
    "    count, division = np.histogram(mydf[column])\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.hist(count)\n",
    "    counter += 1\n",
    "plt.show()\n",
    "plt.savefig('hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o boxplot\n",
    "counter = 1\n",
    "plt.figure(figsize = (7,7))\n",
    "for column in mydf:\n",
    "    plt.subplot(4,3,int(counter))\n",
    "    plt.title(column)\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    mydf.boxplot(column, grid=False)\n",
    "    counter += 1\n",
    "plt.show()\n",
    "plt.savefig('boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####PROBARRRR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import random\n",
    "\n",
    "size_col = 5\n",
    "N_test = 10\n",
    "size_subset = int(mydf.shape[0]/10)\n",
    "print('size subset ' + str(size_subset))\n",
    "x_subset = np.zeros([size_subset,size_col+1])\n",
    "\n",
    "mydf_data = mydf.get_values()\n",
    "\n",
    "for n_test in range(0,N_test):\n",
    "    print( n_test )\n",
    "    x_row = random.sample(range(1, mydf.shape[0]), size_subset)\n",
    "    x_row = np.sort(x_row)\n",
    "#     print(x_row)\n",
    "\n",
    "#     print( mydf.shape )\n",
    "    x_col = random.sample(range(0, mydf_data.shape[1]-1), size_col)\n",
    "    x_col = np.sort(x_col)\n",
    "#     print(x_col)\n",
    "    \n",
    "    c = 0\n",
    "    \n",
    "    for idj in range(0, mydf_data.shape[1]-1):\n",
    "#         print('idj ' + str(idj) + ' ' + str(x_col[c]))\n",
    "        for idx_subset in range(0,size_subset):\n",
    "            if( idj == x_col[c] ):\n",
    "                x_subset[idx_subset,c] = mydf_data[x_row[idx_subset],x_col[c]]\n",
    "#         print(c)\n",
    "        if(idj == x_col[c]):\n",
    "            c += 1\n",
    "        if( c == size_col ):\n",
    "            break;\n",
    "        \n",
    "    \n",
    "    for idx_subset in range(0,size_subset):\n",
    "        x_subset[idx_subset,x_subset.shape[1]-1] = mydf_data[x_row[idx_subset],mydf_data.shape[1]-1]\n",
    "\n",
    "#     print(x_subset)\n",
    "\n",
    "    x_st = x_subset[:,0:x_subset.shape[1]-1]\n",
    "    y_st = x_subset[:,x_subset.shape[1]-1]\n",
    "#     print(x_subset[:,0:x_subset.shape[1]-1])\n",
    "#     print(x_subset[:,x_subset.shape[1]-1])\n",
    "        \n",
    "    clf = MLPRegressor(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001).fit(x_st,y_st)\n",
    "    # print(clf.predict(x_t))\n",
    "    print(clf.score(x_st,y_st))\n",
    "    print( np.sum((y_st - clf.predict(x_st))*(y_st - clf.predict(x_st))) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
