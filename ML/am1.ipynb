{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "%pylab inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def save_value(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x / y\n",
    "\n",
    "def ConfusionMatrix(y_true,y_predict):\n",
    "    CM=confusion_matrix(y_true, y_pred)\n",
    "    return CM\n",
    "\n",
    "# Multiclass Confusion Matrix\n",
    "# Entries:\n",
    "# y_true: true values of the classification\n",
    "# y_predict: predict values of the classification\n",
    "# C: quantity of classes \n",
    "\n",
    "# Haciendo la matriz de confusion binaria para la clase i\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def MultiClassConfusionMatrix(y_true,y_pred):\n",
    "    \n",
    "    C= np.unique(y_true)\n",
    "    D=len(C)\n",
    "    \n",
    "    # Matriz de confusion general \n",
    "    CM=confusion_matrix(y_true, y_pred)\n",
    "    #print('###### General Confusion Matrix #####')\n",
    "    #print(CM)\n",
    "        \n",
    "    accuracy=np.zeros(D)\n",
    "    precision=np.zeros(D)\n",
    "    recall=np.zeros(D)\n",
    "    specificity=np.zeros(D)\n",
    "    \n",
    "    \n",
    "    for i in range(D):\n",
    "        #atrib=np.array(C)\n",
    "        #print('aquiii')\n",
    "        #print(C)\n",
    "        atributo=C[i]\n",
    "        row_i=CM[i,:]\n",
    "        col_i=CM[:,i]\n",
    "        \n",
    "        row_i_without_i=np.delete(row_i,i,0)\n",
    "        #print(row_i_without_i)\n",
    "        col_i_without_i=np.delete(col_i,i,0)\n",
    "        del_row_i=np.delete(CM,i,0)\n",
    "        del_col_i=np.delete(del_row_i,i,1)\n",
    "        \n",
    "        VP=CM[i,i]\n",
    "        #print(VP)\n",
    "        FN=np.sum(row_i_without_i)\n",
    "        #print(VN)\n",
    "        FP=np.sum(col_i_without_i)\n",
    "        VN=np.sum(del_col_i)\n",
    "#         print('VP VN FP FN', VP, VN,FP,FN )\n",
    "        \n",
    "        CM_new=[[VP,FN],[FP,VN]]\n",
    "        #print(CM_new)\n",
    "        CM_new=np.array(CM_new) # casting\n",
    "\n",
    "        # calculando las medidas de desempenho\n",
    "        div1=VP+VN+FP+FN\n",
    "        #print(div1)\n",
    "        div2=VP+FP\n",
    "        div3=VP+FN\n",
    "        div4=VN+FP\n",
    "        \n",
    "        accuracy[i]=save_value((VP+VN),div1)\n",
    "        precision[i]=save_value(VP,div2)\n",
    "        recall[i]=save_value(VP,div3)\n",
    "        specificity[i]=save_value(VN,div4)\n",
    "        \n",
    "        #print('###### Confusion Matrix para clase ',atributo, ' #####')\n",
    "        #print(CM_new)    \n",
    "        \n",
    "    Table = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'specificity': specificity}\n",
    "    df = pd.DataFrame(data=Table)\n",
    "    print(df)\n",
    "    #print(accuracy.shape)\n",
    "#     return accuracy\n",
    "    #print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('porto-seguro-safe-driver-prediction/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "target = train['target']\n",
    "print(type(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['target', 'id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.900378</td>\n",
       "      <td>1.358943</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.983789</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.388544</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_ind_01  ps_ind_02_cat      ps_ind_03  ps_ind_04_cat  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        1.900378       1.358943       4.423318       0.416794   \n",
       "std         1.983789       0.664594       2.699902       0.493311   \n",
       "min         0.000000      -1.000000       0.000000      -1.000000   \n",
       "25%         0.000000       1.000000       2.000000       0.000000   \n",
       "50%         1.000000       1.000000       4.000000       0.000000   \n",
       "75%         3.000000       2.000000       6.000000       1.000000   \n",
       "max         7.000000       4.000000      11.000000       1.000000   \n",
       "\n",
       "       ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.405188       0.393742       0.257033       0.163921   \n",
       "std         1.350642       0.488579       0.436998       0.370205   \n",
       "min        -1.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       1.000000       0.000000   \n",
       "max         6.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_09_bin  ps_ind_10_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
       "mean        0.185304       0.000373  ...       5.441382       1.441918   \n",
       "std         0.388544       0.019309  ...       2.332871       1.202963   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  595212.000000  595212.000000   595212.000000   595212.000000   \n",
       "mean        2.872288       7.539026        0.122427        0.627840   \n",
       "std         1.694887       2.746652        0.327779        0.483381   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      23.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   595212.000000   595212.000000   595212.000000   595212.000000  \n",
       "mean         0.554182        0.287182        0.349024        0.153318  \n",
       "std          0.497056        0.452447        0.476662        0.360295  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace(-1, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['ps_reg_03','ps_car_03_cat','ps_car_05_cat'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace(np.NaN, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_17_bin',\n",
      "       'ps_reg_02', 'ps_car_02_cat', 'ps_car_04_cat', 'ps_car_07_cat',\n",
      "       'ps_car_12', 'ps_car_13'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Select features according to the k highest scores\n",
    "#Using f_regression that is an univariate linear regression tests, \n",
    "#The correlation between each regressor and the target is computed \n",
    "#It is converted to an F score then to a p-value\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "X_best=SelectKBest(f_regression, k=10)\n",
    "X_new=X_best.fit_transform(train,target)\n",
    "\n",
    "mask = X_best.get_support()\n",
    "new_features = train.columns[mask]\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=train[['ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_17_bin',\n",
    "       'ps_reg_02', 'ps_car_02_cat', 'ps_car_04_cat', 'ps_car_07_cat',\n",
    "       'ps_car_12', 'ps_car_13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_15',\n",
      "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_reg_01', 'ps_reg_02',\n",
      "       'ps_car_02_cat', 'ps_car_04_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
      "       'ps_car_12', 'ps_car_13', 'ps_car_15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Select features according to the k highest scores\n",
    "#Using f_regression that is an univariate linear regression tests, \n",
    "#The correlation between each regressor and the target is computed \n",
    "#It is converted to an F score then to a p-value\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "X_best=SelectKBest(f_regression, k=15)\n",
    "X_new=X_best.fit_transform(train,target)\n",
    "\n",
    "mask = X_best.get_support()\n",
    "new_features = train.columns[mask]\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=train[['ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_15',\n",
    "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_reg_01', 'ps_reg_02',\n",
    "       'ps_car_02_cat', 'ps_car_04_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
    "       'ps_car_12', 'ps_car_13', 'ps_car_15']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f67f3f914a8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure();\n",
    "target.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 595212 points : 55164\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = train\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(iris, target).predict(iris)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (iris.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  specificity\n",
      "0   0.90732   0.965809  0.936985     0.123076\n",
      "1   0.90732   0.068797  0.123076     0.936985\n"
     ]
    }
   ],
   "source": [
    "MultiClassConfusionMatrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 595212 points : 55527\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = train1\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(iris, target).predict(iris)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (iris.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  specificity\n",
      "0  0.906711   0.965939  0.936194     0.127270\n",
      "1  0.906711   0.070156  0.127270     0.936194\n"
     ]
    }
   ],
   "source": [
    "MultiClassConfusionMatrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 595212 points : 57976\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = train2\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(iris, target).predict(iris)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (iris.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  specificity\n",
      "0  0.902596   0.966145  0.931554     0.137043\n",
      "1  0.902596   0.070404  0.137043     0.931554\n"
     ]
    }
   ],
   "source": [
    "MultiClassConfusionMatrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 595212 points : 21480\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "iris = train1\n",
    "clf = tree.DecisionTreeClassifier(max_depth=10)\n",
    "y_pred = clf.fit(iris, target).predict(iris)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (iris.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  specificity\n",
      "0  0.963912   0.963941  0.999953     0.011109\n",
      "1  0.963912   0.899254  0.011109     0.999953\n"
     ]
    }
   ],
   "source": [
    "MultiClassConfusionMatrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 595212 points : 21444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "iris = train2\n",
    "clf = tree.DecisionTreeClassifier(max_depth=10)\n",
    "y_pred = clf.fit(iris, target).predict(iris)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (iris.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  specificity\n",
      "0  0.963973   0.963993  0.999960     0.012584\n",
      "1  0.963973   0.922297  0.012584     0.999960\n"
     ]
    }
   ],
   "source": [
    "MultiClassConfusionMatrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of feature_names, 54 does not match number of features, 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-eb6ca307df4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"second_tree\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                  \u001b[0;34m\"does not match number of features, %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                                  % (len(feature_names),\n\u001b[0;32m--> 427\u001b[0;31m                                     decision_tree.n_features_))\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# The depth of each node for plotting with 'leaf' option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of feature_names, 54 does not match number of features, 15"
     ]
    }
   ],
   "source": [
    "import graphviz \n",
    "from graphviz import Source\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, feature_names=train.columns)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"second_tree\",view = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
